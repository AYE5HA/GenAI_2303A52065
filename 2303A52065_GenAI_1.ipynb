{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEnMzaYdp5RbR+HlyMuAzV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AYE5HA/GenAI_2303A52065/blob/main/2303A52065_GenAI_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YActual = [20, 30, 50, 30.3, 50.6]\n",
        "YPred = [20.5, 40, 60, 40.2, 60.7]"
      ],
      "metadata": {
        "id": "QAQPog8l3Kf-"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAE_manual = sum([abs(a - p) for a, p in zip(YActual, YPred)]) / len(YActual)\n",
        "MSE_manual = sum([(a - p)**2 for a, p in zip(YActual, YPred)]) / len(YActual)\n",
        "RMSE_manual = MSE_manual**0.5"
      ],
      "metadata": {
        "id": "LsrYgRgg3yeI"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "MAE_lib = mean_absolute_error(YActual, YPred)\n",
        "MSE_lib = mean_squared_error(YActual, YPred)\n",
        "RMSE_lib = MSE_lib**0.5"
      ],
      "metadata": {
        "id": "0eTT3nho37DH"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Metric\\tManual\\tLibrary\")\n",
        "print(f\"MAE\\t{MAE_manual:.4f}\\t{MAE_lib:.4f}\")\n",
        "print(f\"MSE\\t{MSE_manual:.4f}\\t{MSE_lib:.4f}\")\n",
        "print(f\"RMSE\\t{RMSE_manual:.4f}\\t{RMSE_lib:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zkBapxny4BEy",
        "outputId": "cb91894e-beb2-485d-a7ec-89888cf87def"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric\tManual\tLibrary\n",
            "MAE\t8.1000\t8.1000\n",
            "MSE\t80.0540\t80.0540\n",
            "RMSE\t8.9473\t8.9473\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "YActual = [0, 0, 0, 0, 0, 0, 0, 1, 2, 2, 1, 1, 1, 1, 1]\n",
        "YPred = [0, 0, 0, 0, 0, 0, 1, 2, 2, 2, 1, 0, 2, 0, 2]"
      ],
      "metadata": {
        "id": "u0mkvMUY9XE7"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "correct_predictions = sum(1 for a, p in zip(YActual, YPred) if a == p)\n",
        "accuracy_manual = correct_predictions / len(YActual)\n",
        "class_1_actual = [1 if a == 1 else 0 for a in YActual]\n",
        "class_1_pred = [1 if p == 1 else 0 for p in YPred]\n",
        "true_positives = sum(1 for a, p in zip(class_1_actual, class_1_pred) if a == 1 and p == 1)\n",
        "false_positives = sum(1 for a, p in zip(class_1_actual, class_1_pred) if a == 0 and p == 1)\n",
        "false_negatives = sum(1 for a, p in zip(class_1_actual, class_1_pred) if a == 1 and p == 0)\n",
        "precision_manual = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0\n",
        "recall_manual = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0\n",
        "f1_score_manual = 2 * (precision_manual * recall_manual) / (precision_manual + recall_manual) if (precision_manual + recall_manual) > 0 else 0"
      ],
      "metadata": {
        "id": "ytQgMpe79dzp"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "accuracy_lib = accuracy_score(YActual, YPred)\n",
        "precision_lib = precision_score(YActual, YPred, average='weighted', zero_division=0) #for multi-class\n",
        "recall_lib = recall_score(YActual, YPred, average='weighted', zero_division=0)  #for multi-class\n",
        "f1_score_lib = f1_score(YActual, YPred, average='weighted', zero_division=0)    #for multi-class"
      ],
      "metadata": {
        "id": "-PIOcvXa9p72"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Metric\\tManual\\tLibrary\")\n",
        "print(f\"Accuracy\\t{accuracy_manual:.4f}\\t{accuracy_lib:.4f}\")\n",
        "print(f\"Precision\\t{precision_manual:.4f}\\t{precision_lib:.4f}\")\n",
        "print(f\"Recall\\t\\t{recall_manual:.4f}\\t{recall_lib:.4f}\")\n",
        "print(f\"F1-Score\\t{f1_score_manual:.4f}\\t{f1_score_lib:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Jasr29-9x69",
        "outputId": "c929ebb3-403d-48f0-fbd4-8896335ffe27"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Metric\tManual\tLibrary\n",
            "Accuracy\t0.6000\t0.6000\n",
            "Precision\t0.5000\t0.6033\n",
            "Recall\t\t0.1667\t0.6000\n",
            "F1-Score\t0.2500\t0.5495\n"
          ]
        }
      ]
    }
  ]
}